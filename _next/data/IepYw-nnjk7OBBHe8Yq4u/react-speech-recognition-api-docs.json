{"pageProps":{"title":"React Speech Recognition API docs","contentHtml":"<h2>Interface</h2>\n<ul>\n<li><a href=\"#useSpeechRecognition\">useSpeechRecognition</a></li>\n<li><a href=\"#SpeechRecognition\">SpeechRecognition</a></li>\n</ul>\n<p><a name=\"useSpeechRecognition\"></a></p>\n<h2>useSpeechRecognition</h2>\n<p>React hook for consuming speech recorded by the microphone. Import with:</p>\n<pre><code>import { useSpeechRecognition } from 'react-speech-recognition'\n</code></pre>\n<h3>Input props</h3>\n<p>These are passed as an object argument to <code>useSpeechRecognition</code>:</p>\n<pre><code>useSpeechRecognition({ transcribing, clearTranscriptOnListen, commands })\n</code></pre>\n<h4>transcribing [bool]</h4>\n<p>Is this component collecting a transcript or not? This is independent of the global <code>listening</code> state of the microphone. <code>true</code> by default.</p>\n<h4>clearTranscriptOnListen [bool]</h4>\n<p>Does this component clear its transcript when the microphone is turned on? Has no effect when continuous listening is enabled. <code>true</code> by default.</p>\n<h4>commands [list]</h4>\n<p>See <a href=\"/react-speech-recognition#commands\">Commands</a>.</p>\n<h3>Output state</h3>\n<p>These are returned from <code>useSpeechRecognition</code>:</p>\n<pre><code>  const {\n    transcript,\n    interimTranscript,\n    finalTranscript,\n    resetTranscript,\n    listening,\n    browserSupportsSpeechRecognition,\n    isMicrophoneAvailable,\n  } = useSpeechRecognition()\n</code></pre>\n<h4>transcript [string]</h4>\n<p>Transcription of all speech that has been spoken into the microphone. Is equivalent to the final transcript followed by the interim transcript, separated by a space.</p>\n<h4>resetTranscript [function]</h4>\n<p>Sets <code>transcript</code> to an empty string.</p>\n<h4>listening [bool]</h4>\n<p>If true, the Web Speech API is listening to speech from the microphone.</p>\n<h4>interimTranscript [string]</h4>\n<p>Transcription of speech that the Web Speech API is still processing (i.e. it's still deciding what has just been spoken).</p>\n<p>For the current words being spoken, the interim transcript reflects each successive guess made by the transcription algorithm. When the browserâ€™s confidence in its guess is maximized, it is added to the final transcript.</p>\n<p>The difference between interim and final transcripts can be illustrated by an example over four iterations of the transcription algorithm:</p>\n<img src=\"images/transcript-table.png\" width=\"300\" alt=\"A series of transcripts that grow as more speech is transcribed\">\n<h4>finalTranscript [string]</h4>\n<p>Transcription of speech that the Web Speech API has finished processing.</p>\n<h4>browserSupportsSpeechRecognition [bool]</h4>\n<p>The Web Speech API is not supported on all browsers, so it is recommended that you render some fallback content if it is not supported by the user's browser:</p>\n<pre><code>if (!browserSupportsSpeechRecognition) {\n  // Render some fallback content\n}\n</code></pre>\n<h4>browserSupportsContinuousListening [bool]</h4>\n<p>Continuous listening is not supported on all browsers, so it is recommended that you apply some fallback behaviour if your web app uses continuous listening and is running on a browser that doesn't support it:</p>\n<pre><code>if (browserSupportsContinuousListening) {\n  SpeechRecognition.startListening({ continuous: true })\n} else {\n  // Fallback behaviour\n}\n</code></pre>\n<h4>isMicrophoneAvailable [bool]</h4>\n<p>The user has to give permission for their microphone to be used before transcription can begin. They are asked for permission when <code>react-speech-recognition</code> first tries to start listening. This state will become <code>false</code> if they deny access. In this case, it's advised that you disable voice-driven features and indicate that microphone access is needed for them to work.</p>\n<pre><code>if (!isMicrophoneAvailable) {\n  // Render some fallback content\n}\n</code></pre>\n<p><a name=\"SpeechRecognition\"></a></p>\n<h2>SpeechRecognition</h2>\n<p>Object providing functions to manage the global state of the microphone. Import with:</p>\n<pre><code>import SpeechRecognition from 'react-speech-recognition'\n</code></pre>\n<h3>Functions</h3>\n<h4>startListening (async)</h4>\n<p>Start listening to speech.</p>\n<pre><code>SpeechRecognition.startListening()\n</code></pre>\n<p>This is an asynchronous function, so it will need to be awaited if you want to do something after the microphone has been turned on.</p>\n<p>It can be called with an options argument. For example:</p>\n<pre><code>SpeechRecognition.startListening({\n  continuous: true,\n  language: 'zh-CN'\n})\n</code></pre>\n<p>The following options are available:</p>\n<h5>continuous [bool]</h5>\n<p>By default, the microphone will stop listening when the user stops speaking (<code>continuous: false</code>). This reflects the approach taken by \"press to talk\" buttons on modern devices.</p>\n<p>If you want to listen continuously, set the <code>continuous</code> property to <code>true</code> when calling <code>startListening</code>. The microphone will continue to listen, even after the user has stopped speaking.</p>\n<pre><code>SpeechRecognition.startListening({ continuous: true })\n</code></pre>\n<p><a name=\"language\"></a></p>\n<h5>language [string]</h5>\n<p>To listen for a specific language, you can pass a language tag (e.g. <code>'zh-CN'</code> for Chinese) when calling <code>startListening</code>.</p>\n<pre><code>SpeechRecognition.startListening({ language: 'zh-CN' })\n</code></pre>\n<p>Some known supported languages (based on <a href=\"http://stackoverflow.com/a/14302134/338039\">this Stack Overflow post</a>):</p>\n<ul>\n<li>Afrikaans <code>af</code></li>\n<li>Basque <code>eu</code></li>\n<li>Bulgarian <code>bg</code></li>\n<li>Catalan <code>ca</code></li>\n<li>Arabic (Egypt) <code>ar-EG</code></li>\n<li>Arabic (Jordan) <code>ar-JO</code></li>\n<li>Arabic (Kuwait) <code>ar-KW</code></li>\n<li>Arabic (Lebanon) <code>ar-LB</code></li>\n<li>Arabic (Qatar) <code>ar-QA</code></li>\n<li>Arabic (UAE) <code>ar-AE</code></li>\n<li>Arabic (Morocco) <code>ar-MA</code></li>\n<li>Arabic (Iraq) <code>ar-IQ</code></li>\n<li>Arabic (Algeria) <code>ar-DZ</code></li>\n<li>Arabic (Bahrain) <code>ar-BH</code></li>\n<li>Arabic (Lybia) <code>ar-LY</code></li>\n<li>Arabic (Oman) <code>ar-OM</code></li>\n<li>Arabic (Saudi Arabia) <code>ar-SA</code></li>\n<li>Arabic (Tunisia) <code>ar-TN</code></li>\n<li>Arabic (Yemen) <code>ar-YE</code></li>\n<li>Czech <code>cs</code></li>\n<li>Dutch <code>nl-NL</code></li>\n<li>English (Australia) <code>en-AU</code></li>\n<li>English (Canada) <code>en-CA</code></li>\n<li>English (India) <code>en-IN</code></li>\n<li>English (New Zealand) <code>en-NZ</code></li>\n<li>English (South Africa) <code>en-ZA</code></li>\n<li>English(UK) <code>en-GB</code></li>\n<li>English(US) <code>en-US</code></li>\n<li>Finnish <code>fi</code></li>\n<li>French <code>fr-FR</code></li>\n<li>Galician <code>gl</code></li>\n<li>German <code>de-DE</code></li>\n<li>Greek  <code>el-GR</code></li>\n<li>Hebrew <code>he</code></li>\n<li>Hungarian <code>hu</code></li>\n<li>Icelandic <code>is</code></li>\n<li>Italian <code>it-IT</code></li>\n<li>Indonesian <code>id</code></li>\n<li>Japanese <code>ja</code></li>\n<li>Korean <code>ko</code></li>\n<li>Latin <code>la</code></li>\n<li>Mandarin Chinese <code>zh-CN</code></li>\n<li>Taiwanese <code>zh-TW</code></li>\n<li>Cantonese <code>zh-HK</code></li>\n<li>Malaysian <code>ms-MY</code></li>\n<li>Norwegian <code>no-NO</code></li>\n<li>Polish <code>pl</code></li>\n<li>Pig Latin <code>xx-piglatin</code></li>\n<li>Portuguese <code>pt-PT</code></li>\n<li>Portuguese (Brasil) <code>pt-br</code></li>\n<li>Romanian <code>ro-RO</code></li>\n<li>Russian <code>ru</code></li>\n<li>Serbian <code>sr-SP</code></li>\n<li>Slovak <code>sk</code></li>\n<li>Spanish (Argentina) <code>es-AR</code></li>\n<li>Spanish (Bolivia) <code>es-BO</code></li>\n<li>Spanish (Chile) <code>es-CL</code></li>\n<li>Spanish (Colombia) <code>es-CO</code></li>\n<li>Spanish (Costa Rica) <code>es-CR</code></li>\n<li>Spanish (Dominican Republic) <code>es-DO</code></li>\n<li>Spanish (Ecuador) <code>es-EC</code></li>\n<li>Spanish (El Salvador) <code>es-SV</code></li>\n<li>Spanish (Guatemala) <code>es-GT</code></li>\n<li>Spanish (Honduras) <code>es-HN</code></li>\n<li>Spanish (Mexico) <code>es-MX</code></li>\n<li>Spanish (Nicaragua) <code>es-NI</code></li>\n<li>Spanish (Panama) <code>es-PA</code></li>\n<li>Spanish (Paraguay) <code>es-PY</code></li>\n<li>Spanish (Peru) <code>es-PE</code></li>\n<li>Spanish (Puerto Rico) <code>es-PR</code></li>\n<li>Spanish (Spain) <code>es-ES</code></li>\n<li>Spanish (US) <code>es-US</code></li>\n<li>Spanish (Uruguay) <code>es-UY</code></li>\n<li>Spanish (Venezuela) <code>es-VE</code></li>\n<li>Swedish <code>sv-SE</code></li>\n<li>Turkish <code>tr</code></li>\n<li>Zulu <code>zu</code></li>\n</ul>\n<h4>stopListening (async)</h4>\n<p>Turn the microphone off, but still finish processing any speech in progress.</p>\n<pre><code>SpeechRecognition.stopListening()\n</code></pre>\n<p>This is an asynchronous function, so it will need to be awaited if you want to do something after the microphone has been turned off.</p>\n<h4>abortListening (async)</h4>\n<p>Turn the microphone off, and cancel the processing of any speech in progress.</p>\n<pre><code>SpeechRecognition.abortListening()\n</code></pre>\n<p>This is an asynchronous function, so it will need to be awaited if you want to do something after the microphone has been turned off.</p>\n<h4>getRecognition</h4>\n<p>This returns the underlying <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition\">object</a> used by Web Speech API.</p>\n<h4>applyPolyfill</h4>\n<p>Replace the native Speech Recognition engine (if there is one) with a custom implementation of the <a href=\"https://wicg.github.io/speech-api/#speechreco-section\">W3C SpeechRecognition specification</a>. If there is a Speech Recognition implementation already listening to the microphone, this will be turned off. See <a href=\"/polyfills\">Polyfills</a> for more information on how to use this.</p>\n<pre><code>SpeechRecognition.applyPolyfill(SpeechRecognitionPolyfill)\n</code></pre>\n"},"__N_SSG":true}